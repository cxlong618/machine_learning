#!/usr/bin/env python3
"""
è®­ç»ƒä¼˜åŒ–é…ç½®å™¨ - æ ¹æ®ç¡¬ä»¶è‡ªåŠ¨ä¼˜åŒ–è®­ç»ƒå‚æ•°
"""
import sys
import json
import os

def detect_hardware():
    """æ£€æµ‹ç¡¬ä»¶é…ç½®"""
    try:
        import torch
        hardware_info = {
            'cuda_available': torch.cuda.is_available(),
            'cpu_count': os.cpu_count(),
        }

        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            hardware_info['gpu_count'] = gpu_count

            # è·å–GPUä¿¡æ¯
            gpus = []
            for i in range(gpu_count):
                props = torch.cuda.get_device_properties(i)
                gpu_info = {
                    'name': torch.cuda.get_device_name(i),
                    'memory_gb': props.total_memory / 1e9,
                    'compute_capability': f"{props.major}.{props.minor}",
                    'multiprocessor_count': props.multiprocessor_count
                }
                gpus.append(gpu_info)

            hardware_info['gpus'] = gpus
            hardware_info['total_gpu_memory'] = sum(gpu['memory_gb'] for gpu in gpus)

        return hardware_info
    except ImportError:
        return {'cuda_available': False, 'cpu_count': os.cpu_count()}

def recommend_training_config(hardware_info):
    """æ ¹æ®ç¡¬ä»¶æ¨èè®­ç»ƒé…ç½®"""
    config = {}

    if not hardware_info.get('cuda_available', False):
        # CPUé…ç½®
        config = {
            'script': 'cpu_train.py',
            'batch_size': 8,
            'learning_rate': '2e-5',
            'num_epochs': 3,
            'max_length': 64,
            'description': 'CPUè®­ç»ƒé…ç½® - å°æ‰¹æ¬¡å¤§å°å’ŒçŸ­åºåˆ—',
            'training_time_hours': 6,  # ä¼°è®¡æ—¶é—´
        }
    else:
        # GPUé…ç½®
        total_memory = hardware_info.get('total_gpu_memory', 8)
        gpu_count = hardware_info.get('gpu_count', 1)

        if total_memory >= 24:
            # é«˜ç«¯GPUé…ç½®
            config = {
                'script': 'gpu_train.py',
                'batch_size': 64,
                'learning_rate': '3e-5',
                'num_epochs': 5,
                'max_length': 128,
                'description': 'é«˜ç«¯GPUé…ç½® (â‰¥24GB) - å¤§æ‰¹æ¬¡å¿«é€Ÿè®­ç»ƒ',
                'training_time_hours': 1,
                'estimated_speedup': '10-20x CPU'
            }
        elif total_memory >= 16:
            # ä¸­é«˜ç«¯GPUé…ç½®
            config = {
                'script': 'gpu_train.py',
                'batch_size': 48,
                'learning_rate': '3e-5',
                'num_epochs': 5,
                'max_length': 128,
                'description': 'ä¸­é«˜ç«¯GPUé…ç½® (16-24GB) - ä¸­å¤§æ‰¹æ¬¡',
                'training_time_hours': 2,
                'estimated_speedup': '8-15x CPU'
            }
        elif total_memory >= 12:
            # ä¸­ç«¯GPUé…ç½®
            config = {
                'script': 'gpu_train.py',
                'batch_size': 32,
                'learning_rate': '2.5e-5',
                'num_epochs': 5,
                'max_length': 128,
                'description': 'ä¸­ç«¯GPUé…ç½® (12-16GB) - å¹³è¡¡æ‰¹æ¬¡å¤§å°',
                'training_time_hours': 3,
                'estimated_speedup': '6-12x CPU'
            }
        elif total_memory >= 8:
            # å…¥é—¨çº§GPUé…ç½®
            config = {
                'script': 'src/train.py',  # ä½¿ç”¨åŸå§‹è„šæœ¬ä½†ä¼˜åŒ–
                'batch_size': 16,
                'learning_rate': '2e-5',
                'num_epochs': 8,
                'max_length': 96,
                'description': 'å…¥é—¨çº§GPUé…ç½® (8-12GB) - ä¸­ç­‰æ‰¹æ¬¡å¤§å°',
                'training_time_hours': 4,
                'estimated_speedup': '5-8x CPU'
            }
        else:
            # ä½ç«¯GPUé…ç½®
            config = {
                'script': 'src/train.py',
                'batch_size': 8,
                'learning_rate': '2e-5',
                'num_epochs': 10,
                'max_length': 64,
                'description': 'ä½ç«¯GPUé…ç½® (<8GB) - å°æ‰¹æ¬¡å¤§å°',
                'training_time_hours': 6,
                'estimated_speedup': '3-5x CPU'
            }

    return config

def generate_training_command(config, train_path='data/train.csv', val_path='data/val.csv'):
    """ç”Ÿæˆè®­ç»ƒå‘½ä»¤"""
    script = config['script']

    base_cmd = f"python {script}"

    if script == 'gpu_train.py' or script == 'cpu_train.py':
        # ä¼˜åŒ–è„šæœ¬ä¸éœ€è¦é¢å¤–å‚æ•°
        cmd = base_cmd
    else:
        # åŸå§‹è„šæœ¬éœ€è¦å®Œæ•´å‚æ•°
        params = [
            f"--train_path {train_path}",
            f"--val_path {val_path}",
            f"--batch_size {config['batch_size']}",
            f"--learning_rate {config['learning_rate']}",
            f"--num_epochs {config['num_epochs']}",
            f"--max_length {config['max_length']}"
        ]
        cmd = f"{base_cmd} {' '.join(params)}"

    return cmd

def main():
    print("ğŸ–¥ï¸  ç¡¬ä»¶æ£€æµ‹ä¸è®­ç»ƒä¼˜åŒ–")
    print("=" * 60)

    # æ£€æµ‹ç¡¬ä»¶
    print("æ£€æµ‹ç¡¬ä»¶é…ç½®...")
    hardware = detect_hardware()

    print(f"CPUæ ¸å¿ƒæ•°: {hardware['cpu_count']}")
    print(f"CUDAå¯ç”¨: {'æ˜¯' if hardware['cuda_available'] else 'å¦'}")

    if hardware.get('cuda_available'):
        print(f"GPUæ•°é‡: {hardware['gpu_count']}")
        print(f"GPUä¿¡æ¯:")
        for i, gpu in enumerate(hardware.get('gpus', [])):
            print(f"  GPU {i}: {gpu['name']} ({gpu['memory_gb']:.1f}GB)")
            print(f"      è®¡ç®—èƒ½åŠ›: {gpu['compute_capability']}")

    print()

    # æ¨èé…ç½®
    print("æ¨èè®­ç»ƒé…ç½®:")
    print("-" * 40)
    config = recommend_training_config(hardware)

    for key, value in config.items():
        if key != 'description':
            print(f"  {key}: {value}")

    print(f"\nğŸ“ é…ç½®è¯´æ˜:")
    print(f"  {config['description']}")
    print(f"  â±ï¸  é¢„è®¡è®­ç»ƒæ—¶é—´: {config.get('training_time_hours', 'N/A')}å°æ—¶")
    if 'estimated_speedup' in config:
        print(f"  ğŸš€ ç›¸æ¯”CPUé€Ÿåº¦æå‡: {config['estimated_speedup']}")

    # ç”Ÿæˆè®­ç»ƒå‘½ä»¤
    cmd = generate_training_command(config)
    print(f"\nğŸš€ æ¨èè®­ç»ƒå‘½ä»¤:")
    print(f"  {cmd}")

    # ä¿å­˜é…ç½®
    config_file = 'training_config.json'
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump({
            'hardware': hardware,
            'recommended_config': config,
            'command': cmd
        }, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ’¾ é…ç½®å·²ä¿å­˜åˆ°: {config_file}")

    print("\nğŸ¯ å¿«é€Ÿå¼€å§‹:")
    print("1. è¿è¡Œä¸Šé¢çš„æ¨èå‘½ä»¤")
    print("2. æˆ–è€…è¿è¡Œä¼˜åŒ–åçš„è„šæœ¬:")

    if hardware.get('cuda_available'):
        print("   python gpu_train.py  # GPUä¼˜åŒ–ç‰ˆæœ¬")
    else:
        print("   python cpu_train.py  # CPUç¨³å®šç‰ˆæœ¬")

    print("3. æˆ–è€…æ‰‹åŠ¨è®­ç»ƒ:")
    print("   python src/train.py --train_path data/train.csv --val_path data/val.csv")

    print("\n" + "=" * 60)
    print("ğŸ”§ è®­ç»ƒä¼˜åŒ–å»ºè®®:")

    if hardware.get('cuda_available'):
        total_memory = hardware.get('total_gpu_memory', 8)
        if total_memory < 8:
            print("- è€ƒè™‘ä½¿ç”¨æ›´å°çš„max_length (64-96)")
            print("- å¯ç”¨æ¢¯åº¦ç´¯ç§¯ä»¥æ¨¡æ‹Ÿæ›´å¤§çš„æ‰¹æ¬¡")
        else:
            print("- ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒå‡å°‘å†…å­˜ä½¿ç”¨")
            print("- å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ä»¥èŠ‚çœå†…å­˜")
            print("- ä½¿ç”¨æ›´å¤§çš„æ‰¹æ¬¡å¤§å°å……åˆ†åˆ©ç”¨GPU")

        print("- ç›‘æ§GPUå†…å­˜ä½¿ç”¨æƒ…å†µ")
        print("- å®šæœŸæ¸…ç†GPUç¼“å­˜")

    print("- ä½¿ç”¨ModelScopeåŠ é€Ÿæ¨¡å‹ä¸‹è½½")
    print("- å¯ç”¨WandBç›‘æ§è®­ç»ƒè¿‡ç¨‹")
    print("- æ ¹æ®éªŒè¯ç»“æœè°ƒæ•´å­¦ä¹ ç‡")

if __name__ == "__main__":
    main()