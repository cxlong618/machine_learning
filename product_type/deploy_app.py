#!/usr/bin/env python3
"""
äº§å“åˆ†ç±»Webéƒ¨ç½²åº”ç”¨
åŸºäºFastAPIçš„RESTful APIæœåŠ¡
"""
import os
import sys
import logging
from pathlib import Path
from contextlib import asynccontextmanager

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
src_path = str(Path(__file__).parent / "src")
if src_path not in sys.path:
    sys.path.insert(0, src_path)

from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import uvicorn
import time
import json
from datetime import datetime
import os

from src.inference import get_inference_instance

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡
inference = None
startup_time = datetime.now()


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶æ‰§è¡Œ
    global inference
    try:
        logger.info("ğŸš€ å¯åŠ¨äº§å“åˆ†ç±»æœåŠ¡...")
        inference = get_inference_instance()
        logger.info("âœ… æ¨ç†å™¨åŠ è½½æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ æ¨ç†å™¨åŠ è½½å¤±è´¥: {e}")
        inference = None

    yield

    # å…³é—­æ—¶æ‰§è¡Œï¼ˆå¦‚æœéœ€è¦ï¼‰
    logger.info("ğŸ‘‹ å…³é—­äº§å“åˆ†ç±»æœåŠ¡")


# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="äº§å“åˆ†ç±»API",
    description="åŸºäºBERTçš„å¤šä»»åŠ¡äº§å“åˆ†ç±»ç³»ç»Ÿ",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json",
    lifespan=lifespan
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ·»åŠ é™æ€æ–‡ä»¶æœåŠ¡
static_dir = Path(__file__).parent / "static"
if static_dir.exists():
    app.mount("/static", StaticFiles(directory="static"), name="static")
else:
    app.logger.warning(f"é™æ€æ–‡ä»¶ç›®å½•ä¸å­˜åœ¨: {static_dir}")


# è¯·æ±‚æ¨¡å‹
class ProductRequest(BaseModel):
    product_name: str = Field(..., description="äº§å“åç§°", min_length=1, max_length=200)
    return_prob: bool = Field(True, description="æ˜¯å¦è¿”å›ç½®ä¿¡åº¦")


class ProductResponse(BaseModel):
    success: bool = Field(..., description="è¯·æ±‚æ˜¯å¦æˆåŠŸ")
    data: Optional[Dict[str, Any]] = Field(None, description="é¢„æµ‹ç»“æœ")
    error: Optional[str] = Field(None, description="é”™è¯¯ä¿¡æ¯")
    response_time: str = Field(..., description="å“åº”æ—¶é—´(ms)")
    timestamp: str = Field(..., description="æ—¶é—´æˆ³")


class BatchRequest(BaseModel):
    products: List[str] = Field(..., description="äº§å“åç§°åˆ—è¡¨", min_length=1, max_length=100)
    return_prob: bool = Field(True, description="æ˜¯å¦è¿”å›ç½®ä¿¡åº¦")


class TopKRequest(BaseModel):
    product_name: str = Field(..., description="äº§å“åç§°", min_length=1, max_length=200)
    k: int = Field(5, description="Top-Kæ•°é‡", ge=1, le=10)


class BatchResponse(BaseModel):
    success: bool
    results: List[Dict[str, Any]]
    total_products: int
    total_time: str
    avg_time: str
    errors: List[str]
    timestamp: str


class HealthResponse(BaseModel):
    status: str
    model_loaded: bool
    uptime: str
    system_info: Dict[str, Any]


@app.get("/", tags=["åŸºç¡€"])
async def root():
    """æ ¹è·¯å¾„ - é‡å®šå‘åˆ°å‰ç«¯é¡µé¢"""
    if os.path.exists("static/index.html"):
        return HTMLResponse(open("static/index.html", encoding='utf-8').read())
    else:
        return {
            "message": "äº§å“åˆ†ç±»APIæœåŠ¡",
            "version": "1.0.0",
            "docs": "/docs",
            "health": "/health"
        }


@app.get("/health", response_model=HealthResponse, tags=["ç³»ç»Ÿ"])
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    uptime = str(datetime.now() - startup_time)

    return {
        "status": "healthy",
        "model_loaded": inference is not None,
        "uptime": uptime,
        "system_info": {
            "version": "1.0.0",
            "model_loaded": inference is not None
        }
    }


@app.post("/classify", response_model=ProductResponse, tags=["åˆ†ç±»"])
async def classify_product(request: ProductRequest):
    """å•ä¸ªäº§å“åˆ†ç±»"""
    if not inference:
        raise HTTPException(status_code=503, detail="æ¨¡å‹æœªåŠ è½½ï¼ŒæœåŠ¡ä¸å¯ç”¨")

    start_time = time.time()

    try:
        logger.info(f"æ”¶åˆ°åˆ†ç±»è¯·æ±‚: {request.product_name}")

        # è°ƒç”¨æ¨ç†å™¨
        result = inference.predict(
            request.product_name,
            return_prob=request.return_prob
        )

        response_time = (time.time() - start_time) * 1000

        logger.info(f"åˆ†ç±»å®Œæˆï¼Œç»“æœ: {result.get('standard_name', 'N/A')}")

        return ProductResponse(
            success=True,
            data=result,
            response_time=f"{response_time:.2f}",
            timestamp=datetime.now().isoformat()
        )

    except Exception as e:
        response_time = (time.time() - start_time) * 1000
        logger.error(f"åˆ†ç±»å¤±è´¥: {e}")
        return ProductResponse(
            success=False,
            error=str(e),
            response_time=f"{response_time:.2f}",
            timestamp=datetime.now().isoformat()
        )


@app.post("/classify/batch", response_model=BatchResponse, tags=["åˆ†ç±»"])
async def classify_batch(request: BatchRequest):
    """æ‰¹é‡äº§å“åˆ†ç±»"""
    if not inference:
        raise HTTPException(status_code=503, detail="æ¨¡å‹æœªåŠ è½½ï¼ŒæœåŠ¡ä¸å¯ç”¨")

    start_time = time.time()
    results = []
    errors = []

    for product_name in request.products:
        try:
            result = inference.predict(
                product_name,
                return_prob=request.return_prob
            )
            results.append({
                "product_name": product_name,
                "result": result,
                "success": True
            })
        except Exception as e:
            error_msg = f"äº§å“ '{product_name}' åˆ†ç±»å¤±è´¥: {str(e)}"
            errors.append(error_msg)
            results.append({
                "product_name": product_name,
                "result": None,
                "success": False,
                "error": str(e)
            })

    total_time = (time.time() - start_time) * 1000
    avg_time = total_time / len(request.products) if request.products else 0

    return BatchResponse(
        success=len(errors) == 0,
        results=results,
        total_products=len(request.products),
        total_time=f"{total_time:.2f}",
        avg_time=f"{avg_time:.2f}",
        errors=errors,
        timestamp=datetime.now().isoformat()
    )


@app.post("/classify/top_k", tags=["åˆ†ç±»"])
async def classify_top_k(request: TopKRequest):
    """Top-Kåˆ†ç±»é¢„æµ‹"""
    if not inference:
        raise HTTPException(status_code=503, detail="æ¨¡å‹æœªåŠ è½½ï¼ŒæœåŠ¡ä¸å¯ç”¨")

    try:
        result = inference.get_top_k_predictions(request.product_name, request.k)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Top-Ké¢„æµ‹å¤±è´¥: {str(e)}")


@app.get("/stats", tags=["ç³»ç»Ÿ"])
async def get_stats():
    """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    uptime = str(datetime.now() - startup_time)

    stats = {
        "uptime": uptime,
        "model_loaded": inference is not None,
        "timestamp": datetime.now().isoformat()
    }

    if inference:
        # æ·»åŠ æ¨ç†å™¨ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        stats["inference_stats"] = {
            "model_loaded": True
        }

    return stats


if __name__ == "__main__":
    uvicorn.run(
        "deploy_app:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )