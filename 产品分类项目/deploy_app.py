#!/usr/bin/env python3
"""
äº§å“åˆ†ç±»Webéƒ¨ç½²åº”ç”¨
åŸºäºFastAPIçš„RESTful APIæœåŠ¡
"""
import os
import sys
import logging
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent / "src"))

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import uvicorn
import time
import json
from datetime import datetime

from inference import get_inference_instance

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="äº§å“åˆ†ç±»API",
    description="åŸºäºBERTçš„å¤šä»»åŠ¡äº§å“åˆ†ç±»ç³»ç»Ÿ",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡
inference = None
startup_time = datetime.now()


# è¯·æ±‚æ¨¡å‹
class ProductRequest(BaseModel):
    product_name: str = Field(..., description="äº§å“åç§°", min_length=1, max_length=200)
    return_prob: bool = Field(True, description="æ˜¯å¦è¿”å›ç½®ä¿¡åº¦")
    top_k: Optional[int] = Field(None, ge=1, le=10, description="Top-Ké¢„æµ‹æ•°é‡")


class ProductResponse(BaseModel):
    success: bool = Field(..., description="è¯·æ±‚æ˜¯å¦æˆåŠŸ")
    data: Optional[Dict[str, Any]] = Field(None, description="é¢„æµ‹ç»“æœ")
    error: Optional[str] = Field(None, description="é”™è¯¯ä¿¡æ¯")
    response_time: str = Field(..., description="å“åº”æ—¶é—´(ms)")
    timestamp: str = Field(..., description="æ—¶é—´æˆ³")


class BatchRequest(BaseModel):
    products: List[str] = Field(..., description="äº§å“åç§°åˆ—è¡¨", min_items=1, max_items=100)
    return_prob: bool = Field(True, description="æ˜¯å¦è¿”å›ç½®ä¿¡åº¦")


class BatchResponse(BaseModel):
    success: bool
    results: List[Dict[str, Any]]
    total_products: int
    total_time: str
    avg_time: str
    errors: List[str]
    timestamp: str


class HealthResponse(BaseModel):
    status: str
    model_loaded: bool
    uptime: str
    system_info: Dict[str, Any]


# å¯åŠ¨äº‹ä»¶
@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–æ¨ç†å™¨"""
    global inference

    try:
        logger.info("ğŸš€ å¯åŠ¨äº§å“åˆ†ç±»æœåŠ¡...")
        inference = get_inference_instance()
        logger.info("âœ… æ¨ç†å™¨åŠ è½½æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ æ¨ç†å™¨åŠ è½½å¤±è´¥: {e}")
        inference = None


@app.get("/", tags=["åŸºç¡€"])
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "äº§å“åˆ†ç±»APIæœåŠ¡",
        "version": "1.0.0",
        "docs": "/docs",
        "health": "/health"
    }


@app.get("/health", response_model=HealthResponse, tags=["ç³»ç»Ÿ"])
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    uptime = datetime.now() - startup_time
    hours, remainder = divmod(uptime.total_seconds(), 3600)
    minutes, seconds = divmod(remainder, 60)

    uptime_str = f"{int(hours)}å°æ—¶{int(minutes)}åˆ†é’Ÿ{int(seconds)}ç§’"

    # è·å–ç³»ç»Ÿä¿¡æ¯
    try:
        import psutil
        import torch
        import platform

        system_info = {
            "platform": platform.system(),
            "python_version": platform.python_version(),
            "cuda_available": torch.cuda.is_available(),
            "cpu_count": psutil.cpu_count(),
            "memory_gb": round(psutil.virtual_memory().total / (1024**3), 1)
        }

        if torch.cuda.is_available():
            system_info["gpu_name"] = torch.cuda.get_device_name()
            system_info["gpu_memory_gb"] = round(torch.cuda.get_device_properties(0).total_memory / (1024**3), 1)

    except ImportError:
        system_info = {"message": "ç³»ç»Ÿä¿¡æ¯æ¨¡å—æœªå®Œå…¨å¯ç”¨"}

    return HealthResponse(
        status="healthy" if inference else "degraded",
        model_loaded=inference is not None,
        uptime=uptime_str,
        system_info=system_info
    )


@app.post("/classify", response_model=ProductResponse, tags=["åˆ†ç±»"])
async def classify_product(request: ProductRequest):
    """å•ä¸ªäº§å“åˆ†ç±»"""
    if not inference:
        raise HTTPException(status_code=503, detail="æ¨¡å‹æœªåŠ è½½ï¼ŒæœåŠ¡ä¸å¯ç”¨")

    start_time = time.time()

    try:
        # è°ƒç”¨æ¨ç†
        result = inference.predict(request.product_name, request.return_prob)

        if 'error' in result:
            response_time = f"{(time.time() - start_time) * 1000:.2f}"
            return ProductResponse(
                success=False,
                error=result['error'],
                response_time=response_time,
                timestamp=datetime.now().isoformat()
            )

        # Top-Ké¢„æµ‹
        if request.top_k:
            try:
                top_k_result = inference.get_top_k_predictions(request.product_name, request.top_k)
                result['top_k_predictions'] = top_k_result
            except Exception as e:
                logger.warning(f"Top-Ké¢„æµ‹å¤±è´¥: {e}")

        response_time = f"{(time.time() - start_time) * 1000:.2f}"

        return ProductResponse(
            success=True,
            data=result,
            response_time=response_time,
            timestamp=datetime.now().isoformat()
        )

    except Exception as e:
        response_time = f"{(time.time() - start_time) * 1000:.2f}"
        logger.error(f"åˆ†ç±»å¤±è´¥: {e}")
        return ProductResponse(
            success=False,
            error=f"åˆ†ç±»å¤±è´¥: {str(e)}",
            response_time=response_time,
            timestamp=datetime.now().isoformat()
        )


@app.post("/classify/batch", response_model=BatchResponse, tags=["åˆ†ç±»"])
async def classify_batch(request: BatchRequest):
    """æ‰¹é‡äº§å“åˆ†ç±»"""
    if not inference:
        raise HTTPException(status_code=503, detail="æ¨¡å‹æœªåŠ è½½ï¼ŒæœåŠ¡ä¸å¯ç”¨")

    start_time = time.time()

    try:
        results = []
        errors = []

        # æ‰¹é‡é¢„æµ‹
        batch_results = inference.predict_batch(request.products, request.return_prob)

        for i, (product_name, result) in enumerate(zip(request.products, batch_results)):
            if 'error' in result:
                errors.append(f"äº§å“ {i+1} ({product_name[:30]}...): {result['error']}")
            else:
                results.append(result)

        total_time = (time.time() - start_time) * 1000
        avg_time = total_time / len(request.products)

        return BatchResponse(
            success=True,
            results=results,
            total_products=len(request.products),
            total_time=f"{total_time:.2f}ms",
            avg_time=f"{avg_time:.2f}ms",
            errors=errors,
            timestamp=datetime.now().isoformat()
        )

    except Exception as e:
        total_time = (time.time() - start_time) * 1000
        logger.error(f"æ‰¹é‡åˆ†ç±»å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡åˆ†ç±»å¤±è´¥: {str(e)}")


@app.post("/classify/top_k", tags=["åˆ†ç±»"])
async def classify_top_k(product_name: str = Field(..., description="äº§å“åç§°"),
                       k: int = Field(5, description="Top-Kæ•°é‡", ge=1, le=10)):
    """Top-Kåˆ†ç±»é¢„æµ‹"""
    if not inference:
        raise HTTPException(status_code=503, detail="æ¨¡å‹æœªåŠ è½½ï¼ŒæœåŠ¡ä¸å¯ç”¨")

    try:
        result = inference.get_top_k_predictions(product_name, k)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Top-Ké¢„æµ‹å¤±è´¥: {str(e)}")


@app.get("/stats", tags=["ç³»ç»Ÿ"])
async def get_stats():
    """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    if not inference:
        raise HTTPException(status_code=503, detail="æ¨¡å‹æœªåŠ è½½ï¼ŒæœåŠ¡ä¸å¯ç”¨")

    try:
        # è¿è¡Œæ€§èƒ½æµ‹è¯•
        perf_stats = inference.evaluate_performance(num_samples=50)

        return {
            "model_info": {
                "model_loaded": True,
                "model_path": inference.model_path
            },
            "performance": perf_stats,
            "service": {
                "uptime": str(datetime.now() - startup_time),
                "timestamp": datetime.now().isoformat()
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")


@app.get("/categories", tags=["ä¿¡æ¯"])
async def get_categories():
    """è·å–æ‰€æœ‰ç±»åˆ«ä¿¡æ¯"""
    try:
        mapping_path = "./models/label_mappings.json"
        if not os.path.exists(mapping_path):
            raise HTTPException(status_code=404, detail="æ ‡ç­¾æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨")

        with open(mapping_path, 'r', encoding='utf-8') as f:
            mappings = json.load(f)

        return {
            "standard_name_categories": mappings['standard_mapping'],
            "level1_categories": mappings['level1_mapping'],
            "level2_categories": mappings['level2_mapping'],
            "level3_categories": mappings['level3_mapping'],
            "total_standard_names": len(mappings['standard_mapping']),
            "total_level1": len(mappings['level1_mapping']),
            "total_level2": len(mappings['level2_mapping']),
            "total_level3": len(mappings['level3_mapping'])
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ç±»åˆ«ä¿¡æ¯å¤±è´¥: {str(e)}")


# é”™è¯¯å¤„ç†
@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    return {
        "error": True,
        "message": exc.detail,
        "status_code": exc.status_code,
        "timestamp": datetime.now().isoformat()
    }


@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    logger.error(f"æœªå¤„ç†çš„å¼‚å¸¸: {exc}")
    return {
        "error": True,
        "message": "å†…éƒ¨æœåŠ¡å™¨é”™è¯¯",
        "timestamp": datetime.now().isoformat()
    }


def main():
    """å¯åŠ¨æœåŠ¡å™¨"""
    print("ğŸš€ å¯åŠ¨äº§å“åˆ†ç±»APIæœåŠ¡")
    print("="*50)
    print("ğŸ“‹ æœåŠ¡ä¿¡æ¯:")
    print("  - APIæ–‡æ¡£: http://localhost:8000/docs")
    print("  - ReDocæ–‡æ¡£: http://localhost:8000/redoc")
    print("  - å¥åº·æ£€æŸ¥: http://localhost:8000/health")
    print("="*50)

    uvicorn.run(
        "deploy_app:app",
        host="0.0.0.0",
        port=8000,
        reload=False,
        workers=1,
        log_level="info"
    )


if __name__ == "__main__":
    main()